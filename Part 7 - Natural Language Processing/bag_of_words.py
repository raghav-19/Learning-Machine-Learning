# -*- coding: utf-8 -*-
"""bag_of_words.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_Gl8eCH3tZI2dfj3x3GBS02dt9j43bAW

##Importing Libraries and Dataset
"""

import numpy as np;
import pandas as pd;
import matplotlib.pyplot as plt;
dataset=pd.read_csv("/content/drive/My Drive/Dataset/Restaurant_Reviews.tsv",delimiter='\t',quoting=3);
X=dataset.iloc[:,0].values
y=dataset.iloc[:,1].values

"""##Cleaning the Text"""

import re;
import nltk;
nltk.download('stopwords');
from nltk.corpus import stopwords;
from nltk.stem.porter import PorterStemmer;
corpus=[];
all_stopwords=stopwords.words('english');
sub="n't";
my_stopwords=[word for word in all_stopwords if not sub in word];
my_stopwords.remove('not');
my_stopwords.remove('no');
ps=PorterStemmer();
def convert_word(line):
  line=re.sub('[^a-zA-Z]',' ',line);
  line=line.lower();
  line=line.split();
  line=[ps.stem(word) for word in line if not word in set(my_stopwords)];
  return ' '.join(line);
for review in X:
  corpus.append(convert_word(review));

"""##Create Bag of Words Model"""

from sklearn.feature_extraction.text import CountVectorizer;
cv=CountVectorizer(max_features=1500);
x=cv.fit_transform(corpus).toarray();

"""##Splitting Dataset & Training Model"""

from sklearn.model_selection import train_test_split;
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20);
from sklearn.svm import SVC;
model=SVC(kernel='linear')
model.fit(x_train,y_train);

"""##Predicting Result for test cases, Making Confusion Matrix """

y_pred=model.predict(x_test);
from sklearn.metrics import confusion_matrix;
print(confusion_matrix(y_test,y_pred));
from sklearn.metrics import accuracy_score;
print(accuracy_score(y_test,y_pred));